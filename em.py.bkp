import numpy as np
import matplotlib.pyplot as plt

# Initialization
def initialize_parameters(N, D, K):
    p = np.random.uniform(0, 1, size=(K, D))
    mix_pi = np.full((K, 1), 1/K)
    return p, mix_pi

# E-Step
def EStep(X, p, mix_pi, K):
    N = X.shape[0]
    eta = np.zeros((N, K))
    
    for i in range(N):
        for k in range(K):
            eta[i, k] = mix_pi[k] * np.prod(np.power(p[k], X[i]) * np.power(1 - p[k], 1 - X[i]))
        eta[i] = eta[i] / np.sum(eta[i])
    
    return eta

# M-Step
def MStep(X, eta, alpha1, alpha2, K, D):
    N = X.shape[0]
    mix_pi = np.zeros(K)
    p = np.zeros((K, D))
    
    for k in range(K):
        mix_pi[k] = np.sum(eta[:, k]) / N
        
        numerator = np.dot(eta[:, k], X) + alpha1 - 1
        denominator = np.sum(eta[:, k]) + alpha1 + alpha2 - 2
        p[k] = numerator / denominator
        
    return p, mix_pi

# Full EM Algorithm
def EM(X, K, iter, alpha1=1e-3, alpha2=1e-3):
    N, D = X.shape
    p, mix_pi = initialize_parameters(N, D, K)
    
    for _ in range(iter):
        eta = EStep(X, p, mix_pi, K)
        p, mix_pi = MStep(X, eta, alpha1, alpha2, K, D)
    
    return p, mix_pi

# Visualization
def visualize_parameters(p):
    
    K = p.shape[0]
    for k in range(K):
        plt.imshow(p[k].reshape(28, 28), cmap='gray')
        plt.show()




# Load MNIST dataset
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Preprocess the images: Flatten and binarize
flatten_images = train_images.reshape(-1, 28*28) / 255.0
binary_images = (flatten_images > 0.5).astype(np.float32)

# Sample 1000 datapoints randomly
sample_indices = np.random.choice(binary_images.shape[0], 1000, replace=False)
X = binary_images[sample_indices]

# Choose the number of clusters
K = 5  # Example: you can change this value

# Run the EM algorithm
p, mix_pi = EM(X, K, iter=20)

# Visualize the resulting Bernoulli parameters
visualize_parameters(p)
